# app.py
# -*- coding: utf-8 -*-

"""
(V2 Refactor + Filetree/README) Streamlit ä¸»åº”ç”¨ç¨‹åºï¼Œæ•´åˆäº†é‡æ„åçš„æ¨¡å—ã€‚
- ä½¿ç”¨ src/ ç›®å½•ä¸‹çš„ä»£ç è§£æã€é¢„å¤„ç†ã€å›¾æ„å»ºå’Œ RAG æ¨¡å—ã€‚
- RAG Handler è´Ÿè´£å¤„ç†é¡¹ç›®ç‰¹å®šçš„ç´¢å¼•/ç¼“å­˜å’Œ LLM äº¤äº’ã€‚
- æ”¯æŒé€šè¿‡é…ç½®é€‰æ‹©ä¸åŒçš„ LLM æä¾›å•†å’Œæ¨¡å‹ã€‚
- æ–°å¢ï¼šæ˜¾ç¤ºæ–‡ä»¶æ ‘ç»“æ„å’Œ README å†…å®¹ã€‚
"""

import streamlit as st
import os
import logging
import networkx as nx
import pickle
from streamlit_agraph import agraph, Node, Edge, Config
from typing import Dict, List, Any, Optional, Tuple

# --- Import Refactored Modules ---
# Ensure src is importable (e.g., by running streamlit run app.py from the project root)
try:
    from src.utils import config_loader as cfg # Load config early to set logging
    from src import code_parser
    from src import preprocessing
    from src import graph_builder
    from src.rag_handler import RAGHandler # Import the class
except ImportError as e:
     st.error(f"Failed to import necessary modules from 'src/'. Make sure you run streamlit from the project root directory. Error: {e}")
     st.stop() # Stop execution if imports fail


# --- Basic Setup ---
logger = logging.getLogger(__name__) # Get logger configured by config_loader

# Define filename for preprocessed data cache within project data dir
PREPROCESSED_DATA_FILENAME = "preprocessed_chunks.pkl"

# --- Helper Function for Agraph Conversion (Updated Styles) ---
def convert_nx_to_agraph(graph: nx.DiGraph) -> Tuple[List[Node], List[Edge]]:
    """å°† NetworkX å›¾è½¬æ¢ä¸º streamlit-agraph éœ€è¦çš„èŠ‚ç‚¹å’Œè¾¹åˆ—è¡¨ã€‚"""
    agraph_nodes = []
    agraph_edges = []

    if not graph:
        return agraph_nodes, agraph_edges

    # --- Define styles for new node types ---
    node_styles = {
        'project': {'color': '#FFD700', 'shape': 'star', 'size': 30},
        'directory': {'color': '#C0C0C0', 'shape': 'box', 'size': 20},
        'file': {'color': '#ADD8E6', 'shape': 'ellipse', 'size': 10},
        'readme': {'color': '#98FB98', 'shape': 'box', 'size': 15},
        'function': {'color': '#74A9D8', 'shape': 'dot', 'size': 15},
        'class': {'color': '#F0A367', 'shape': 'box', 'size': 20},
        'module': {'color': '#90EE90', 'shape': 'database', 'size': 25},
        'unknown': {'color': '#CCCCCC', 'shape': 'ellipse', 'size': 10}
    }

    # --- Edge styles ---
    edge_styles = {
        'CONTAINS': {'color': '#E0E0E0', 'dashes': True, 'label': ''},
        'DEFINES': {'color': '#B0E0E6', 'dashes': False, 'label': ''},
        'CALLS': {'color': '#ADD8E6', 'dashes': False},
        'DEPENDS_ON': {'color': '#FFA07A', 'dashes': True},
        'IMPLEMENTS': {'color': '#FFB6C1', 'dashes': False},
        'RELATES_TO': {'color': '#D3D3D3', 'dashes': True},
        'MODULE_SUMMARY_FOR': {'color': '#90EE90', 'dashes': True, 'label': 'summary'},
    }
    default_edge_color = "#CCCCCC"


    for node_id, node_data in graph.nodes(data=True):
        node_type = node_data.get('type', 'unknown')
        style = node_styles.get(node_type, node_styles['unknown'])
        node_label = str(node_data.get('short_name', node_data.get('label', node_id)))

        agraph_nodes.append(Node(id=node_id,
                                 label=node_label,
                                 title=node_data.get('title', ''),
                                 size=style['size'],
                                 shape=style['shape'],
                                 color=style['color']
                                 ))

    for u, v, edge_data in graph.edges(data=True):
        if u not in graph or v not in graph:
            logger.warning(f"Skipping edge ({u} -> {v}) because one or both nodes do not exist in the graph node set.")
            continue

        edge_type = edge_data.get('type', 'UNKNOWN')
        style = edge_styles.get(edge_type, {'color': default_edge_color, 'dashes': False, 'label': edge_type})
        edge_label = str(style.get('label', edge_data.get('label', '')))

        agraph_edges.append(Edge(source=u,
                                 target=v,
                                 label=edge_label,
                                 type="CURVE_SMOOTH",
                                 color=style['color'],
                                 dashes=style['dashes']
                                 ))

    return agraph_nodes, agraph_edges


# --- Streamlit App UI ---
st.set_page_config(layout="wide", page_title="Python ä»£ç åˆ†æå™¨ (Filetree Enhanced)")
st.title("ğŸ Python AST & RAG ä»£ç åˆ†æå™¨ (Filetree Enhanced)")

# --- Session State Initialization ---
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = True
    st.session_state.project_dir = "."
    st.session_state.analysis_done = False
    st.session_state.analysis_error = None
    st.session_state.all_nodes_info = None
    st.session_state.all_imports_info = None
    st.session_state.file_tree = None
    st.session_state.readme_content = None
    st.session_state.preprocessed_chunks = None
    st.session_state.graph = None
    st.session_state.agraph_nodes = []
    st.session_state.agraph_edges = []
    st.session_state.rag_handler_instance = None
    st.session_state.selected_node_id = None
    st.session_state.selected_context_ids = []
    st.session_state.project_report = ""
    st.session_state.project_report_error = None
    st.session_state.last_rag_question = ""
    st.session_state.last_rag_answer = ""
    logger.info("Streamlit session state initialized.")


# --- Sidebar ---
st.sidebar.header("é¡¹ç›®é€‰æ‹© (Project Selection)")
project_dir_input = st.sidebar.text_input("è¾“å…¥ Python é¡¹ç›®ç›®å½•è·¯å¾„:", st.session_state.project_dir)
analyze_button = st.sidebar.button("åˆ†æé¡¹ç›® (Analyze Project)", key="analyze_btn")

# Display analysis status or errors in sidebar
if st.session_state.analysis_done and not st.session_state.analysis_error:
     st.sidebar.success(f"åˆ†æå®Œæˆ: {os.path.basename(st.session_state.project_dir)}")
elif st.session_state.analysis_error:
     st.sidebar.error(f"åˆ†æå¤±è´¥: {st.session_state.analysis_error}")


# --- Main Analysis Logic ---
if analyze_button:
    abs_project_dir = os.path.abspath(project_dir_input)
    if os.path.isdir(abs_project_dir):
        st.session_state.project_dir = abs_project_dir
        # Reset state for new analysis
        st.session_state.analysis_done = False
        st.session_state.analysis_error = None
        st.session_state.all_nodes_info = None
        st.session_state.all_imports_info = None
        st.session_state.file_tree = None
        st.session_state.readme_content = None
        st.session_state.preprocessed_chunks = None
        st.session_state.graph = None
        st.session_state.agraph_nodes = []
        st.session_state.agraph_edges = []
        st.session_state.rag_handler_instance = None
        st.session_state.selected_node_id = None
        st.session_state.selected_context_ids = []
        st.session_state.project_report = ""
        st.session_state.project_report_error = None
        st.session_state.last_rag_question = ""
        st.session_state.last_rag_answer = ""

        st.sidebar.info(f"å¼€å§‹åˆ†æ: {st.session_state.project_dir}")
        logger.info(f"Starting analysis for project: {st.session_state.project_dir}")

        # --- Execute Full Pipeline ---
        try:
            # 0. Initialize RAG Handler
            with st.spinner("æ­¥éª¤ 0/5: åˆå§‹åŒ– RAG ç³»ç»Ÿ..."):
                 try:
                      st.session_state.rag_handler_instance = RAGHandler(project_path=st.session_state.project_dir)
                      project_data_dir = st.session_state.rag_handler_instance.project_data_dir
                      preprocessed_data_path = os.path.join(project_data_dir, PREPROCESSED_DATA_FILENAME)
                      logger.info("RAG Handler initialized.")
                 except ValueError as rag_init_err:
                      st.error(f"æ— æ³•åˆå§‹åŒ– RAG ç³»ç»Ÿ: {rag_init_err}")
                      st.session_state.analysis_error = f"RAG Init failed: {rag_init_err}"
                      st.stop()


            # 1. Parsing (Updated Call)
            with st.spinner("æ­¥éª¤ 1/5: æ­£åœ¨è§£æ Python æ–‡ä»¶å’Œæ‰«ææ–‡ä»¶æ ‘..."):
                nodes, imports, tree, readme = code_parser.parse_project(st.session_state.project_dir)
                st.session_state.all_nodes_info = nodes
                st.session_state.all_imports_info = imports
                st.session_state.file_tree = tree
                st.session_state.readme_content = readme

                if not st.session_state.all_nodes_info and not st.session_state.all_imports_info:
                    st.warning("è§£æé¡¹ç›®æ—¶æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ Python èŠ‚ç‚¹æˆ–å¯¼å…¥ã€‚")
                logger.info(f"è§£æå’Œæ–‡ä»¶æ ‘æ‰«æå®Œæˆã€‚")


            # 2. Preprocessing
            with st.spinner("æ­¥éª¤ 2/5: æ­£åœ¨é¢„å¤„ç†ä»£ç å— (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)..."):
                 loaded_from_cache = False
                 if os.path.exists(preprocessed_data_path):
                      logger.info(f"å°è¯•ä»ç¼“å­˜åŠ è½½é¢„å¤„ç†æ•°æ®: {preprocessed_data_path}")
                      try:
                          with open(preprocessed_data_path, 'rb') as f:
                              st.session_state.preprocessed_chunks = pickle.load(f)
                          logger.info(f"æˆåŠŸåŠ è½½ {len(st.session_state.preprocessed_chunks)} ä¸ªé¢„å¤„ç†å—ã€‚")
                          loaded_from_cache = True
                      except Exception as load_err:
                           logger.warning(f"åŠ è½½é¢„å¤„ç†ç¼“å­˜å¤±è´¥: {load_err}ã€‚å°†é‡æ–°ç”Ÿæˆã€‚")
                           st.session_state.preprocessed_chunks = None

                 if not loaded_from_cache:
                      logger.info("æ‰§è¡Œ preprocessing.preprocess_project...")
                      st.session_state.preprocessed_chunks = preprocessing.preprocess_project(
                          st.session_state.all_nodes_info or {},
                          st.session_state.all_imports_info or {}
                      )
                      if not st.session_state.preprocessed_chunks:
                           st.warning("é¢„å¤„ç†æ­¥éª¤æœªç”Ÿæˆä»»ä½•ä»£ç å—ã€‚")
                      else:
                           try:
                                with open(preprocessed_data_path, 'wb') as f:
                                     pickle.dump(st.session_state.preprocessed_chunks, f)
                                logger.info(f"é¢„å¤„ç†ç»“æœå·²ä¿å­˜åˆ°ç¼“å­˜: {preprocessed_data_path}")
                           except Exception as save_err:
                                logger.error(f"ä¿å­˜é¢„å¤„ç†ç»“æœå¤±è´¥: {save_err}")
                 logger.info("é¢„å¤„ç†å®Œæˆã€‚")


            # 3. RAG Indexing
            with st.spinner("æ­¥éª¤ 3/5: æ­£åœ¨æ„å»º/åŠ è½½ RAG ç´¢å¼•..."):
                 if st.session_state.rag_handler_instance and st.session_state.preprocessed_chunks:
                      st.session_state.rag_handler_instance.build_index(
                          st.session_state.preprocessed_chunks,
                          force_rebuild=True
                      )
                      if st.session_state.rag_handler_instance.index is None:
                           st.warning("æ„å»º RAG ç´¢å¼•å¤±è´¥æˆ–ç´¢å¼•ä¸ºç©ºã€‚")
                 elif not st.session_state.preprocessed_chunks:
                      st.info("æ²¡æœ‰é¢„å¤„ç†æ•°æ®å¯ç”¨äºæ„å»º RAG ç´¢å¼•ã€‚")
                 logger.info("RAG ç´¢å¼•å¤„ç†å®Œæˆã€‚")


            # 4. Graph Building (Updated Call)
            with st.spinner("æ­¥éª¤ 4/5: æ­£åœ¨æ„å»ºä¾èµ–å›¾ (å«æ–‡ä»¶ç»“æ„)..."):
                 if st.session_state.preprocessed_chunks is not None:
                     st.session_state.graph = graph_builder.build_dependency_graph_v2(
                         st.session_state.preprocessed_chunks,
                         st.session_state.all_nodes_info or {},
                         st.session_state.all_imports_info or {},
                         st.session_state.file_tree or [],
                         st.session_state.readme_content,
                         st.session_state.project_dir
                     )
                 else:
                      st.warning("é¢„å¤„ç†æ­¥éª¤æœªç”Ÿæˆæœ‰æ•ˆæ•°æ®å—ï¼Œæ— æ³•æ„å»ºè¯¦ç»†å›¾è°±ã€‚ä»…æ˜¾ç¤ºæ–‡ä»¶ç»“æ„ã€‚")
                      st.session_state.graph = graph_builder.build_dependency_graph_v2(
                          [], {}, {},
                          st.session_state.file_tree or [],
                          st.session_state.readme_content,
                          st.session_state.project_dir
                      )

                 if not st.session_state.graph or len(st.session_state.graph.nodes) == 0:
                     st.warning("æœªèƒ½æ„å»ºæœ‰æ•ˆçš„ä¾èµ–å›¾æˆ–å›¾ä¸ºç©ºã€‚")
                     st.session_state.graph = nx.DiGraph()
                 logger.info("å›¾æ„å»ºå®Œæˆã€‚")


            # Convert graph for agraph display
            st.session_state.agraph_nodes, st.session_state.agraph_edges = convert_nx_to_agraph(st.session_state.graph)


            # 5. Initial Project Report Generation (Enhanced with README context)
            with st.spinner("æ­¥éª¤ 5/5: æ­£åœ¨ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š..."):
                 if st.session_state.rag_handler_instance:
                    try:
                        report_query = "ä¸ºè¿™ä¸ª Python é¡¹ç›®ç”Ÿæˆä¸€ä¸ªé«˜çº§åˆ«çš„æŠ€æœ¯æ¦‚è§ˆæŠ¥å‘Šï¼Œæ¶µç›–å…¶ä¸»è¦æ¨¡å—ã€æ ¸å¿ƒåŠŸèƒ½å’Œæ½œåœ¨çš„æ¶æ„æ¨¡å¼ã€‚(Generate a high-level technical overview report for this Python project, covering main modules, core functionalities, and potential architectural patterns.)"
                        base_context_query = "project overview structure modules functionality architecture"
                        report_context_chunks = st.session_state.rag_handler_instance.retrieve(base_context_query, k=4)

                        # --- Enhancement: Add README to context ---
                        if st.session_state.readme_content:
                            readme_node_id = next((nid for nid, data in st.session_state.graph.nodes(data=True) if data.get('type') == 'readme'), 'README.md')
                            readme_chunk_for_rag = {
                                'id': readme_node_id,
                                'filepath': 'README.md',
                                'type': 'readme',
                                'summary': 'é¡¹ç›®è‡ªè¿°æ–‡ä»¶ (Project Readme file)',
                                'code': st.session_state.readme_content[:1000] + "..."
                            }
                            # Prepend README context for higher priority
                            report_context_chunks.insert(0, readme_chunk_for_rag) # *** Corrected Indentation Here ***
                            logger.info("Added README content to project report context.")
                        # --- End Enhancement ---

                        # --- Corrected Indentation for the following block ---
                        if report_context_chunks:
                            st.session_state.project_report = st.session_state.rag_handler_instance.generate_response(
                                report_query,
                                report_context_chunks
                            )
                        else:
                            st.session_state.project_report = st.session_state.rag_handler_instance.generate_response(report_query, [])
                            st.info("æœªèƒ½æ‰¾åˆ°ç”ŸæˆæŠ¥å‘Šçš„ç‰¹å®šä¸Šä¸‹æ–‡ï¼Œå°è¯•ç›´æ¥ç”Ÿæˆã€‚")

                        if st.session_state.project_report.startswith("[ç”Ÿæˆå›ç­”æ—¶å‡ºé”™"):
                            st.session_state.project_report_error = st.session_state.project_report
                            st.session_state.project_report = ""

                    except Exception as report_err:
                        logger.error(f"ç”Ÿæˆé¡¹ç›®æŠ¥å‘Šå¤±è´¥: {report_err}", exc_info=True)
                        st.session_state.project_report_error = f"[ç”Ÿæˆé¡¹ç›®æŠ¥å‘Šæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {report_err}]"
                        st.session_state.project_report = ""
                 # --- End Corrected Indentation ---


            # --- Analysis Complete ---
            st.session_state.analysis_done = True
            st.sidebar.success("åˆ†æå®Œæˆï¼(Analysis Complete!)")
            st.rerun()

        except Exception as e:
            logger.error(f"åˆ†ææµç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            st.error(f"åˆ†æå¤±è´¥: {e}")
            st.session_state.analysis_error = str(e)
            st.session_state.analysis_done = False
            st.rerun()

    else:
        st.sidebar.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç›®å½•è·¯å¾„ã€‚(Please enter a valid directory path.)")


# --- Main Area Layout ---
col1, col2 = st.columns([3, 2])

# --- Left Column: Graph Display ---
with col1:
    st.subheader("é¡¹ç›®ç»“æ„å›¾ (å«æ–‡ä»¶æ ‘)")
    if st.session_state.analysis_done and st.session_state.agraph_nodes:
        config = Config(width=1200, height=1000, directed=True, physics=True, hierarchical=False,
                        physics_options={
                            "enabled": True,
                            "barnesHut": {"gravitationalConstant": -10000, "springConstant": 0.05, "springLength": 200},
                            "minVelocity": 0.75,
                        },
                        interaction={"hover": True, "tooltipDelay": 300, "navigationButtons": True, "keyboard": True},
                        node={'labelProperty': 'label'},
                        edge={'labelProperty': 'label'}
                       )

        clicked_node_id = agraph(nodes=st.session_state.agraph_nodes,
                                 edges=st.session_state.agraph_edges,
                                 config=config)

        if clicked_node_id and clicked_node_id != st.session_state.selected_node_id:
            st.session_state.selected_node_id = clicked_node_id
            st.session_state.last_rag_question = ""
            st.session_state.last_rag_answer = ""
            st.rerun()

    elif st.session_state.analysis_done:
        st.info("åˆ†æå®Œæˆï¼Œä½†å›¾ä¸­æ²¡æœ‰èŠ‚ç‚¹å¯æ˜¾ç¤ºã€‚")
    elif st.session_state.analysis_error:
         st.warning(f"åˆ†æå¤±è´¥ï¼Œæ— æ³•æ˜¾ç¤ºå›¾è¡¨ã€‚é”™è¯¯ï¼š{st.session_state.analysis_error}")
    else:
        st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©é¡¹ç›®å¹¶ç‚¹å‡» 'åˆ†æé¡¹ç›®'ã€‚")


# --- Right Column: Tabs for Details and RAG ---
with col2:
    if st.session_state.analysis_done:
        tab1, tab2 = st.tabs(["ğŸ“Š é¡¹ç›®æŠ¥å‘Š & README", "ğŸ’¬ äº’åŠ¨åˆ†æ"])

        # --- Tab 1: Project Report & README ---
        with tab1:
            st.subheader("è‡ªåŠ¨é¡¹ç›®æŠ¥å‘Š")
            if st.session_state.project_report_error:
                 st.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {st.session_state.project_report_error}")
            elif st.session_state.project_report:
                st.markdown(st.session_state.project_report)
            else:
                st.info("æ­£åœ¨ç”Ÿæˆæˆ–æ— å¯ç”¨æŠ¥å‘Šã€‚")

            # --- Display README ---
            st.markdown("---")
            st.subheader("README.md å†…å®¹")
            readme_content_display = "*æœªæ‰¾åˆ° README.md æˆ–å†…å®¹ä¸å¯ç”¨*"
            if st.session_state.graph:
                readme_node_id = next((nid for nid, data in st.session_state.graph.nodes(data=True) if data.get('type') == 'readme'), None)
                if readme_node_id and readme_node_id in st.session_state.graph.nodes:
                    readme_content_display = st.session_state.graph.nodes[readme_node_id].get('content', readme_content_display)

            if readme_content_display == "*æœªæ‰¾åˆ° README.md æˆ–å†…å®¹ä¸å¯ç”¨*" and st.session_state.readme_content:
                readme_content_display = st.session_state.readme_content

            if readme_content_display != "*æœªæ‰¾åˆ° README.md æˆ–å†…å®¹ä¸å¯ç”¨*":
                 st.markdown(readme_content_display, unsafe_allow_html=True)
            else:
                 st.info(readme_content_display)
            # --- End README Display ---


        # --- Tab 2: Interactive Analysis ---
        with tab2:
            st.subheader("äº’åŠ¨åˆ†æ")

            # Display selected node details
            selected_node_data = None
            if st.session_state.selected_node_id and st.session_state.graph:
                if st.session_state.selected_node_id in st.session_state.graph.nodes:
                    selected_node_data = st.session_state.graph.nodes[st.session_state.selected_node_id]
                    node_type_display = selected_node_data.get('type', 'N/A')
                    node_path_display = selected_node_data.get('filepath', st.session_state.selected_node_id)

                    st.markdown(f"#### é€‰ä¸­èŠ‚ç‚¹: `{selected_node_data.get('label', st.session_state.selected_node_id)}`")
                    st.markdown(f"**ç±»å‹:** {node_type_display} | **è·¯å¾„:** `{node_path_display}`")
                    if 'lineno' in selected_node_data:
                        st.markdown(f"**è¡Œ:** {selected_node_data.get('lineno', 'N/A')}")

                    # --- Context Management Button ---
                    can_add_to_context = node_type_display not in ['project', 'directory', 'file']
                    if can_add_to_context:
                         is_in_context = st.session_state.selected_node_id in st.session_state.selected_context_ids
                         button_text = "ä»ä¸Šä¸‹æ–‡ä¸­ç§»é™¤" if is_in_context else "åŠ å…¥åˆ°ä¸Šä¸‹æ–‡"
                         if st.button(button_text, key=f"ctx_btn_{st.session_state.selected_node_id}"):
                             if is_in_context:
                                 st.session_state.selected_context_ids.remove(st.session_state.selected_node_id)
                             else:
                                 if st.session_state.selected_node_id not in st.session_state.selected_context_ids:
                                      st.session_state.selected_context_ids.append(st.session_state.selected_node_id)
                             st.rerun()
                    # --- End Context Management ---

                    # --- Display details in expanders ---
                    if node_type_display in ['function', 'class', 'module']:
                         with st.expander("æ‘˜è¦ (Summary)"):
                              summary = selected_node_data.get('summary')
                              st.markdown(summary if summary and not summary.startswith("[") else "*æ— æœ‰æ•ˆæ‘˜è¦*")
                         with st.expander("ä»£ç ç‰‡æ®µ (Code Snippet)"):
                              st.code(selected_node_data.get('code', '# N/A'), language='python')
                         with st.expander("æå–çš„å…³ç³» (Extracted Relationships)"):
                              rels = selected_node_data.get('relationships')
                              if rels: st.json(rels)
                              else: st.markdown("*æœªæå–åˆ°å…³ç³»æˆ–æ— å…³ç³»ã€‚*")
                    elif node_type_display == 'readme':
                         with st.expander("README å†…å®¹é¢„è§ˆ"):
                              st.markdown(selected_node_data.get('content', '*å†…å®¹ä¸å¯ç”¨*')[:1000] + "...")

                    st.divider()
                else:
                    st.warning(f"é€‰ä¸­çš„èŠ‚ç‚¹ ID '{st.session_state.selected_node_id}' åœ¨å›¾ä¸­æœªæ‰¾åˆ°ã€‚è¯·é‡æ–°é€‰æ‹©ã€‚")
                    st.session_state.selected_node_id = None

            else:
                 st.info("è¯·åœ¨å·¦ä¾§å›¾ä¸­ç‚¹å‡»ä¸€ä¸ªèŠ‚ç‚¹ä»¥æŸ¥çœ‹å…¶è¯¦ç»†ä¿¡æ¯ã€‚")


            # Display Current Context
            st.markdown("---")
            st.markdown("**å½“å‰ä¸Šä¸‹æ–‡:**")
            if st.session_state.selected_context_ids:
                 context_display_list = []
                 for ctx_id in st.session_state.selected_context_ids:
                      ctx_node_data = None
                      if st.session_state.graph and ctx_id in st.session_state.graph.nodes:
                           ctx_node_data = st.session_state.graph.nodes[ctx_id]
                           display_name = f"`{ctx_node_data.get('label', ctx_id)}` ({ctx_node_data.get('type', 'N/A')})"
                      else:
                           display_name = f"`{ctx_id}`"
                      context_display_list.append(f"- {display_name}")
                 st.markdown("\n".join(context_display_list))

                 if st.button("æ¸…ç©ºä¸Šä¸‹æ–‡", key="clear_ctx"):
                      st.session_state.selected_context_ids = []
                      st.rerun()
            else:
                 st.markdown("*æœªé€‰æ‹©ä»»ä½•ä¸Šä¸‹æ–‡ã€‚å°†è‡ªåŠ¨æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚*")


            # RAG Q&A Section
            st.markdown("---")
            st.markdown("**æé—®:**")
            question = st.text_area("è¾“å…¥æ‚¨å…³äºä»£ç çš„é—®é¢˜:", key="rag_question_input", value=st.session_state.last_rag_question)
            ask_rag_button = st.button("æé—® (Ask)", key="ask_rag")

            if ask_rag_button and question:
                 st.session_state.last_rag_question = question
                 st.session_state.last_rag_answer = ""
                 retrieved_chunks_for_q: List[Dict[str, Any]] = []

                 if not st.session_state.rag_handler_instance:
                      st.error("RAG ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•å›ç­”é—®é¢˜ã€‚")
                 else:
                      with st.spinner("æ­£åœ¨æ£€ç´¢ç›¸å…³ä»£ç å—..."):
                           try:
                               if st.session_state.selected_context_ids:
                                    logger.info(f"Using {len(st.session_state.selected_context_ids)} selected context nodes for RAG.")
                                    for ctx_id in st.session_state.selected_context_ids:
                                         chunk_data = st.session_state.rag_handler_instance.get_chunk_by_id(ctx_id)
                                         if chunk_data:
                                              retrieved_chunks_for_q.append(chunk_data)
                                              logger.debug(f"Added selected context chunk: {ctx_id}")
                                         else:
                                              if ctx_id in st.session_state.graph.nodes:
                                                   node_data = st.session_state.graph.nodes[ctx_id]
                                                   if node_data.get('type') == 'readme':
                                                         retrieved_chunks_for_q.append({
                                                             'id': ctx_id, 'filepath': ctx_id, 'type': 'readme',
                                                             'summary':'é¡¹ç›®è‡ªè¿°æ–‡ä»¶', 'code': node_data.get('content', '')[:1000]
                                                         })
                                                         logger.debug(f"Added selected context node (README): {ctx_id}")
                                              else:
                                                   logger.warning(f"Could not retrieve chunk data or node data for context ID: {ctx_id}")
                               else:
                                    logger.info("No context selected, performing vector search for RAG.")
                                    retrieved_chunks_for_q = st.session_state.rag_handler_instance.retrieve(question, k=5)

                           except Exception as retrieve_err:
                                st.error(f"æ£€ç´¢æ—¶å‡ºé”™: {retrieve_err}")
                                logger.error("Error during RAG retrieval", exc_info=True)

                      with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                           try:
                                if not retrieved_chunks_for_q:
                                     logger.warning("No context chunks found or selected for generation.")

                                st.session_state.last_rag_answer = st.session_state.rag_handler_instance.generate_response(
                                    question,
                                    retrieved_chunks_for_q
                                )
                           except Exception as gen_err:
                                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {gen_err}")
                                logger.error("Error during RAG generation", exc_info=True)
                                st.session_state.last_rag_answer = "[ç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯]"
                 st.rerun()

            # Display last Q&A
            if st.session_state.last_rag_answer:
                 st.markdown("**å›ç­”:**")
                 st.markdown(st.session_state.last_rag_answer)

    elif st.session_state.analysis_error:
         st.error(f"åˆ†ææœªèƒ½å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¾§è¾¹æ é”™è¯¯ä¿¡æ¯ã€‚")
    else:
        st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©é¡¹ç›®å¹¶ç‚¹å‡» 'åˆ†æé¡¹ç›®' ä»¥å¯åŠ¨ã€‚")