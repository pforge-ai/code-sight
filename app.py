# app.py
# -*- coding: utf-8 -*-

"""
(V2 Refactor) Streamlit ä¸»åº”ç”¨ç¨‹åºï¼Œæ•´åˆäº†é‡æ„åçš„æ¨¡å—ã€‚
- ä½¿ç”¨ src/ ç›®å½•ä¸‹çš„ä»£ç è§£æã€é¢„å¤„ç†ã€å›¾æ„å»ºå’Œ RAG æ¨¡å—ã€‚
- RAG Handler è´Ÿè´£å¤„ç†é¡¹ç›®ç‰¹å®šçš„ç´¢å¼•/ç¼“å­˜å’Œ LLM äº¤äº’ã€‚
- æ”¯æŒé€šè¿‡é…ç½®é€‰æ‹©ä¸åŒçš„ LLM æä¾›å•†å’Œæ¨¡å‹ã€‚
"""

import streamlit as st
import os
import logging
import networkx as nx
import pickle
from streamlit_agraph import agraph, Node, Edge, Config
from typing import Dict, List, Any, Optional, Tuple

# --- Import Refactored Modules ---
# Ensure src is importable (e.g., by running streamlit run app.py from the project root)
try:
    from src.utils import config_loader as cfg # Load config early to set logging
    from src import code_parser
    from src import preprocessing
    from src import graph_builder
    from src.rag_handler import RAGHandler # Import the class
except ImportError as e:
     st.error(f"Failed to import necessary modules from 'src/'. Make sure you run streamlit from the project root directory. Error: {e}")
     st.stop() # Stop execution if imports fail


# --- Basic Setup ---
logger = logging.getLogger(__name__) # Get logger configured by config_loader

# Define filename for preprocessed data cache within project data dir
PREPROCESSED_DATA_FILENAME = "preprocessed_chunks.pkl"

# --- Helper Function for Agraph Conversion (Mostly Unchanged) ---
def convert_nx_to_agraph(graph: nx.DiGraph) -> Tuple[List[Node], List[Edge]]:
    """å°† NetworkX å›¾è½¬æ¢ä¸º streamlit-agraph éœ€è¦çš„èŠ‚ç‚¹å’Œè¾¹åˆ—è¡¨ã€‚"""
    agraph_nodes = []
    agraph_edges = []

    if not graph:
        return agraph_nodes, agraph_edges

    default_node_color = "#CCCCCC"
    node_styles = {
        'function': {'color': '#74A9D8', 'shape': 'dot', 'size': 15},
        'class': {'color': '#F0A367', 'shape': 'box', 'size': 20},
        'module': {'color': '#90EE90', 'shape': 'database', 'size': 25},
        'unknown': {'color': default_node_color, 'shape': 'ellipse', 'size': 10}
    }
    default_edge_color = "#CCCCCC"
    edge_styles = {
        'CONTAINS': {'color': '#90EE90', 'dashes': True, 'label': ''},
        'CALLS': {'color': '#ADD8E6', 'dashes': False},
        'DEPENDS_ON': {'color': '#FFA07A', 'dashes': True},
        'IMPLEMENTS': {'color': '#FFB6C1', 'dashes': False}, # Example for new type
        'RELATES_TO': {'color': '#D3D3D3', 'dashes': True}, # Example for generic relation
        # Add more styles based on relationship types extracted by LLM
    }


    for node_id, node_data in graph.nodes(data=True):
        node_type = node_data.get('type', 'unknown')
        style = node_styles.get(node_type, node_styles['unknown'])

        # Ensure label is a string, use short_name if available
        node_label = str(node_data.get('short_name', node_data.get('label', node_id)))

        agraph_nodes.append(Node(id=node_id,
                                 label=node_label,
                                 title=node_data.get('title', ''), # Hover text comes from graph builder
                                 size=style['size'],
                                 shape=style['shape'],
                                 color=style['color']
                                 ))

    for u, v, edge_data in graph.edges(data=True):
        edge_type = edge_data.get('type', 'UNKNOWN')
        style = edge_styles.get(edge_type, {'color': default_edge_color, 'dashes': False, 'label': edge_type})

        # Ensure label is a string
        edge_label = str(style.get('label', edge_data.get('label', ''))) # Use style label first

        agraph_edges.append(Edge(source=u,
                                 target=v,
                                 label=edge_label,
                                 type="CURVE_SMOOTH", # Edge shape
                                 color=style['color'],
                                 dashes=style['dashes']
                                 ))

    return agraph_nodes, agraph_edges


# --- Streamlit App UI ---
st.set_page_config(layout="wide", page_title="Python ä»£ç åˆ†æå™¨ (Refactored)")
st.title("ğŸ Python AST & RAG ä»£ç åˆ†æå™¨ (Refactored)")

# --- Session State Initialization ---
# Use more robust initialization
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = True
    st.session_state.project_dir = "."
    st.session_state.analysis_done = False
    st.session_state.analysis_error = None
    st.session_state.all_nodes_info = None
    st.session_state.all_imports_info = None
    st.session_state.preprocessed_chunks = None
    st.session_state.graph = None
    st.session_state.agraph_nodes = []
    st.session_state.agraph_edges = []
    st.session_state.rag_handler_instance = None
    st.session_state.selected_node_id = None
    st.session_state.selected_context_ids = [] # List to store IDs added to context
    st.session_state.project_report = ""
    st.session_state.project_report_error = None
    st.session_state.last_rag_question = ""
    st.session_state.last_rag_answer = ""
    logger.info("Streamlit session state initialized.")


# --- Sidebar ---
st.sidebar.header("é¡¹ç›®é€‰æ‹© (Project Selection)")
project_dir_input = st.sidebar.text_input("è¾“å…¥ Python é¡¹ç›®ç›®å½•è·¯å¾„ (Enter Python project directory path):", st.session_state.project_dir)
analyze_button = st.sidebar.button("åˆ†æé¡¹ç›® (Analyze Project)", key="analyze_btn")

# Display analysis status or errors in sidebar
if st.session_state.analysis_done and not st.session_state.analysis_error:
     st.sidebar.success(f"åˆ†æå®Œæˆ: {os.path.basename(st.session_state.project_dir)}")
elif st.session_state.analysis_error:
     st.sidebar.error(f"åˆ†æå¤±è´¥: {st.session_state.analysis_error}")


# --- Main Analysis Logic ---
if analyze_button:
    abs_project_dir = os.path.abspath(project_dir_input)
    if os.path.isdir(abs_project_dir):
        st.session_state.project_dir = abs_project_dir # Store absolute path
        # Reset state for new analysis
        st.session_state.analysis_done = False
        st.session_state.analysis_error = None
        st.session_state.all_nodes_info = None
        st.session_state.all_imports_info = None
        st.session_state.preprocessed_chunks = None
        st.session_state.graph = None
        st.session_state.agraph_nodes = []
        st.session_state.agraph_edges = []
        st.session_state.rag_handler_instance = None # Reset RAG handler
        st.session_state.selected_node_id = None
        st.session_state.selected_context_ids = []
        st.session_state.project_report = ""
        st.session_state.project_report_error = None
        st.session_state.last_rag_question = ""
        st.session_state.last_rag_answer = ""

        st.sidebar.info(f"å¼€å§‹åˆ†æ (Starting analysis): {st.session_state.project_dir}")
        logger.info(f"Starting analysis for project: {st.session_state.project_dir}")

        # --- Execute Full Pipeline ---
        try:
            # 0. Initialize RAG Handler (needs project path for data isolation)
            # Do this early as other steps might depend on its data dir
            with st.spinner("æ­¥éª¤ 0/5: åˆå§‹åŒ– RAG ç³»ç»Ÿ... (Initializing RAG system...)"):
                 try:
                      st.session_state.rag_handler_instance = RAGHandler(project_path=st.session_state.project_dir)
                      project_data_dir = st.session_state.rag_handler_instance.project_data_dir # Get project specific dir
                      preprocessed_data_path = os.path.join(project_data_dir, PREPROCESSED_DATA_FILENAME)
                      logger.info("RAG Handler initialized.")
                 except ValueError as rag_init_err:
                      st.error(f"æ— æ³•åˆå§‹åŒ– RAG ç³»ç»Ÿ: {rag_init_err}")
                      st.session_state.analysis_error = f"RAG Init failed: {rag_init_err}"
                      st.stop() # Stop if RAG handler fails (e.g., missing keys)


            # 1. Parsing
            with st.spinner("æ­¥éª¤ 1/5: æ­£åœ¨è§£æ Python æ–‡ä»¶... (Parsing Python files...)"):
                st.session_state.all_nodes_info, st.session_state.all_imports_info = code_parser.parse_project(st.session_state.project_dir)
                if not st.session_state.all_nodes_info and not st.session_state.all_imports_info:
                    st.warning("è§£æé¡¹ç›®æ—¶æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ Python èŠ‚ç‚¹æˆ–å¯¼å…¥ã€‚è¯·æ£€æŸ¥é¡¹ç›®è·¯å¾„å’Œå¿½ç•¥è§„åˆ™ã€‚(No nodes/imports found. Check path and ignore rules.)")
                    # Allow continuing, maybe project is empty or fully ignored
                logger.info(f"è§£æå®Œæˆã€‚æ‰¾åˆ° {len(st.session_state.all_nodes_info)} ä¸ªæ–‡ä»¶åŒ…å«èŠ‚ç‚¹ã€‚ (Parsing complete.)")


            # 2. Preprocessing (with caching per project)
            with st.spinner("æ­¥éª¤ 2/5: æ­£åœ¨é¢„å¤„ç†ä»£ç å— (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)... (Preprocessing code chunks...)"):
                 # Try loading cached preprocessed data for this project
                 loaded_from_cache = False
                 if os.path.exists(preprocessed_data_path):
                      logger.info(f"å°è¯•ä»ç¼“å­˜åŠ è½½é¢„å¤„ç†æ•°æ®: {preprocessed_data_path}")
                      try:
                          with open(preprocessed_data_path, 'rb') as f:
                              st.session_state.preprocessed_chunks = pickle.load(f)
                          logger.info(f"æˆåŠŸåŠ è½½ {len(st.session_state.preprocessed_chunks)} ä¸ªé¢„å¤„ç†å—ã€‚(Successfully loaded preprocessed data.)")
                          loaded_from_cache = True
                      except Exception as load_err:
                           logger.warning(f"åŠ è½½é¢„å¤„ç†ç¼“å­˜å¤±è´¥: {load_err}ã€‚å°†é‡æ–°ç”Ÿæˆã€‚(Failed to load cache, regenerating.)")
                           st.session_state.preprocessed_chunks = None

                 if not loaded_from_cache:
                      logger.info("æ‰§è¡Œ preprocessing.preprocess_project...")
                      st.session_state.preprocessed_chunks = preprocessing.preprocess_project(
                          st.session_state.all_nodes_info or {}, # Pass empty dict if None
                          st.session_state.all_imports_info or {}
                      )
                      if not st.session_state.preprocessed_chunks:
                           st.warning("é¢„å¤„ç†æ­¥éª¤æœªç”Ÿæˆä»»ä½•ä»£ç å—ã€‚(Preprocessing generated no chunks.)")
                           # Allow continuing, graph/RAG might be empty
                      else:
                           # Save the result to project-specific cache
                           try:
                                with open(preprocessed_data_path, 'wb') as f:
                                     pickle.dump(st.session_state.preprocessed_chunks, f)
                                logger.info(f"é¢„å¤„ç†ç»“æœå·²ä¿å­˜åˆ°ç¼“å­˜: {preprocessed_data_path} (Preprocessed data saved to cache.)")
                           except Exception as save_err:
                                logger.error(f"ä¿å­˜é¢„å¤„ç†ç»“æœå¤±è´¥: {save_err} (Failed to save preprocessed data.)")
                 logger.info("é¢„å¤„ç†å®Œæˆã€‚(Preprocessing complete.)")


            # 3. RAG Indexing (using the initialized handler)
            with st.spinner("æ­¥éª¤ 3/5: æ­£åœ¨æ„å»º/åŠ è½½ RAG ç´¢å¼•... (Building/Loading RAG index...)"):
                 if st.session_state.rag_handler_instance and st.session_state.preprocessed_chunks:
                      # Build index (force_rebuild=True ensures consistency with fresh analysis)
                      # The handler itself tries loading first if files exist, but rebuild ensures freshness for the UI run.
                      # Consider making force_rebuild optional via UI? For now, rebuild.
                      st.session_state.rag_handler_instance.build_index(
                          st.session_state.preprocessed_chunks,
                          force_rebuild=True
                      )
                      if st.session_state.rag_handler_instance.index is None:
                           st.warning("æ„å»º RAG ç´¢å¼•å¤±è´¥æˆ–ç´¢å¼•ä¸ºç©ºã€‚(RAG index build failed or index is empty.)")
                 elif not st.session_state.preprocessed_chunks:
                      st.info("æ²¡æœ‰é¢„å¤„ç†æ•°æ®å¯ç”¨äºæ„å»º RAG ç´¢å¼•ã€‚(No preprocessed data for RAG index.)")
                 logger.info("RAG ç´¢å¼•å¤„ç†å®Œæˆã€‚(RAG index handling complete.)")


            # 4. Graph Building
            with st.spinner("æ­¥éª¤ 4/5: æ­£åœ¨æ„å»ºä¾èµ–å›¾... (Building dependency graph...)"):
                 if st.session_state.preprocessed_chunks:
                     st.session_state.graph = graph_builder.build_dependency_graph_v2(
                         st.session_state.preprocessed_chunks,
                         st.session_state.all_nodes_info or {},
                         st.session_state.all_imports_info or {}
                         # Pass RAG handler if implementing bootstrapping:
                         # rag_handler_instance=st.session_state.rag_handler_instance
                     )
                 if not st.session_state.graph or len(st.session_state.graph.nodes) == 0:
                     st.warning("æœªèƒ½æ„å»ºæœ‰æ•ˆçš„ä¾èµ–å›¾æˆ–å›¾ä¸ºç©ºã€‚(Failed to build graph or graph is empty.)")
                     st.session_state.graph = nx.DiGraph() # Ensure it's an empty graph object
                 logger.info("å›¾æ„å»ºå®Œæˆã€‚(Graph building complete.)")


            # Convert graph for agraph display
            st.session_state.agraph_nodes, st.session_state.agraph_edges = convert_nx_to_agraph(st.session_state.graph)


            # 5. Initial Project Report Generation
            with st.spinner("æ­¥éª¤ 5/5: æ­£åœ¨ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š... (Generating project report...)"):
                 if st.session_state.rag_handler_instance:
                      try:
                           report_query = "ä¸ºè¿™ä¸ª Python é¡¹ç›®ç”Ÿæˆä¸€ä¸ªé«˜çº§åˆ«çš„æŠ€æœ¯æ¦‚è§ˆæŠ¥å‘Šï¼Œæ¶µç›–å…¶ä¸»è¦æ¨¡å—ã€æ ¸å¿ƒåŠŸèƒ½å’Œæ½œåœ¨çš„æ¶æ„æ¨¡å¼ã€‚(Generate a high-level technical overview report for this Python project, covering main modules, core functionalities, and potential architectural patterns.)"
                           # Retrieve context relevant to the whole project (e.g., module summaries)
                           # Use RAG retrieve for broader context search
                           report_context_chunks = st.session_state.rag_handler_instance.retrieve("project overview structure modules functionality architecture", k=5)
                           if not report_context_chunks and st.session_state.preprocessed_chunks:
                                # Fallback: use module chunks directly if retrieval fails
                                report_context_chunks = [c for c in st.session_state.preprocessed_chunks if c.get('type') == 'module']

                           if report_context_chunks:
                                st.session_state.project_report = st.session_state.rag_handler_instance.generate_response(
                                    report_query,
                                    report_context_chunks
                                )
                           else:
                                # Try generating without specific context if none found
                                st.session_state.project_report = st.session_state.rag_handler_instance.generate_response(report_query, [])
                                st.info("æœªèƒ½æ‰¾åˆ°ç”ŸæˆæŠ¥å‘Šçš„ç‰¹å®šä¸Šä¸‹æ–‡ï¼Œå°è¯•ç›´æ¥ç”Ÿæˆã€‚(No specific context found for report, attempting direct generation.)")

                           # Check if report generation itself indicated an error
                           if st.session_state.project_report.startswith("[ç”Ÿæˆå›ç­”æ—¶å‡ºé”™"):
                                st.session_state.project_report_error = st.session_state.project_report
                                st.session_state.project_report = "" # Clear report content
                      except Exception as report_err:
                           logger.error(f"ç”Ÿæˆé¡¹ç›®æŠ¥å‘Šå¤±è´¥: {report_err}", exc_info=True)
                           st.session_state.project_report_error = f"[ç”Ÿæˆé¡¹ç›®æŠ¥å‘Šæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {report_err}]"
                           st.session_state.project_report = ""


            # --- Analysis Complete ---
            st.session_state.analysis_done = True
            st.sidebar.success("åˆ†æå®Œæˆï¼(Analysis Complete!)")
            st.rerun() # Rerun to update the UI state cleanly

        except Exception as e:
            # Catch any unexpected error during the pipeline
            logger.error(f"åˆ†ææµç¨‹ä¸­å‘ç”Ÿé”™è¯¯ (Error during analysis pipeline): {e}", exc_info=True)
            st.error(f"åˆ†æå¤±è´¥ (Analysis failed): {e}")
            st.session_state.analysis_error = str(e)
            st.session_state.analysis_done = False
            st.rerun() # Rerun to show error state

    else:
        st.sidebar.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç›®å½•è·¯å¾„ã€‚(Please enter a valid directory path.)")


# --- Main Area Layout ---
col1, col2 = st.columns([3, 2]) # Graph left, Details/RAG right

# --- Left Column: Graph Display ---
with col1:
    st.subheader("é¡¹ç›®ç»“æ„å›¾ (Project Structure Graph)")
    if st.session_state.analysis_done and st.session_state.agraph_nodes:
        # Configure Agraph (adjust physics/layout as needed)
        config = Config(width=1200, height=1000, directed=True, physics=True, hierarchical=False,
                        # Fine-tune physics for better layout stability
                        physics_options={
                            "enabled": True,
                            "barnesHut": {"gravitationalConstant": -8000, "springConstant": 0.04, "springLength": 150},
                            "minVelocity": 0.75,
                            # "solver": "forceAtlas2Based" # Experiment with solvers
                        },
                        interaction={"hover": True, "tooltipDelay": 300, "navigationButtons": True, "keyboard": True},
                        node={'labelProperty': 'label'},
                        edge={'labelProperty': 'label'}
                       )

        # Display the graph and capture clicked node ID
        clicked_node_id = agraph(nodes=st.session_state.agraph_nodes,
                                 edges=st.session_state.agraph_edges,
                                 config=config)

        # Update selected node in session state if a node was clicked
        if clicked_node_id and clicked_node_id != st.session_state.selected_node_id:
            st.session_state.selected_node_id = clicked_node_id
            # Clear previous RAG explanation when node changes
            st.session_state.last_rag_question = ""
            st.session_state.last_rag_answer = ""
            st.rerun() # Rerun to update the right panel immediately

    elif st.session_state.analysis_done:
        st.info("åˆ†æå®Œæˆï¼Œä½†å›¾ä¸­æ²¡æœ‰èŠ‚ç‚¹å¯æ˜¾ç¤ºã€‚(Analysis complete, but no nodes to display in the graph.)")
    elif st.session_state.analysis_error:
         st.warning(f"åˆ†æå¤±è´¥ï¼Œæ— æ³•æ˜¾ç¤ºå›¾è¡¨ã€‚é”™è¯¯ï¼š{st.session_state.analysis_error} (Analysis failed, cannot display graph.)")
    else:
        st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©é¡¹ç›®å¹¶ç‚¹å‡» 'åˆ†æé¡¹ç›®'ã€‚(Select a project and click 'Analyze Project' on the left.)")


# --- Right Column: Tabs for Details and RAG ---
with col2:
    if st.session_state.analysis_done:
        # Create Tabs
        tab1, tab2 = st.tabs(["ğŸ“Š é¡¹ç›®æŠ¥å‘Š (Project Report)", "ğŸ’¬ äº’åŠ¨åˆ†æ (Interactive Analysis)"])

        # --- Tab 1: Project Report ---
        with tab1:
            st.subheader("è‡ªåŠ¨é¡¹ç›®æŠ¥å‘Š (Automated Project Report)")
            if st.session_state.project_report_error:
                 st.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™ (Error generating report): {st.session_state.project_report_error}")
            elif st.session_state.project_report:
                st.markdown(st.session_state.project_report)
            else:
                st.info("æ­£åœ¨ç”Ÿæˆæˆ–æ— å¯ç”¨æŠ¥å‘Šã€‚(Generating report or no report available.)")

            # Add a button to regenerate report manually
            if st.button("é‡æ–°ç”ŸæˆæŠ¥å‘Š (Regenerate Report)", key="regen_report"):
                 with st.spinner("æ­£åœ¨é‡æ–°ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š... (Regenerating project report...)"):
                      st.session_state.project_report = "" # Clear previous report/error
                      st.session_state.project_report_error = None
                      if st.session_state.rag_handler_instance:
                           try:
                                report_query = "ä¸ºè¿™ä¸ª Python é¡¹ç›®ç”Ÿæˆä¸€ä¸ªé«˜çº§åˆ«çš„æŠ€æœ¯æ¦‚è§ˆæŠ¥å‘Šï¼Œæ¶µç›–å…¶ä¸»è¦æ¨¡å—ã€æ ¸å¿ƒåŠŸèƒ½å’Œæ½œåœ¨çš„æ¶æ„æ¨¡å¼ã€‚(Generate a high-level technical overview report for this Python project, covering main modules, core functionalities, and potential architectural patterns.)"
                                report_context_chunks = st.session_state.rag_handler_instance.retrieve("project overview structure modules functionality architecture", k=5)
                                if not report_context_chunks and st.session_state.preprocessed_chunks:
                                     report_context_chunks = [c for c in st.session_state.preprocessed_chunks if c.get('type') == 'module']

                                if report_context_chunks:
                                     st.session_state.project_report = st.session_state.rag_handler_instance.generate_response(report_query, report_context_chunks)
                                else:
                                     st.session_state.project_report = st.session_state.rag_handler_instance.generate_response(report_query, [])

                                if st.session_state.project_report.startswith("[ç”Ÿæˆå›ç­”æ—¶å‡ºé”™"):
                                     st.session_state.project_report_error = st.session_state.project_report
                                     st.session_state.project_report = ""
                           except Exception as report_err:
                                logger.error(f"é‡æ–°ç”Ÿæˆé¡¹ç›®æŠ¥å‘Šå¤±è´¥: {report_err}", exc_info=True)
                                st.session_state.project_report_error = f"[é‡æ–°ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {report_err}]"
                      else:
                           st.session_state.project_report_error = "RAG ç³»ç»Ÿæœªåˆå§‹åŒ–ã€‚(RAG system not initialized.)"
                      st.rerun() # Update UI


        # --- Tab 2: Interactive Analysis ---
        with tab2:
            st.subheader("äº’åŠ¨åˆ†æ (Interactive Analysis)")

            # Display selected node details
            selected_node_data = None
            if st.session_state.selected_node_id and st.session_state.graph:
                if st.session_state.selected_node_id in st.session_state.graph.nodes:
                    selected_node_data = st.session_state.graph.nodes[st.session_state.selected_node_id]
                    st.markdown(f"#### é€‰ä¸­èŠ‚ç‚¹ (Selected Node): `{selected_node_data.get('short_name', st.session_state.selected_node_id)}`")
                    st.markdown(f"**ç±»å‹ (Type):** {selected_node_data.get('type', 'N/A')} | **æ–‡ä»¶ (File):** `{selected_node_data.get('filepath', 'N/A')}` | **è¡Œ (Line):** {selected_node_data.get('lineno', 'N/A')}")

                    # Context Management Button
                    is_in_context = st.session_state.selected_node_id in st.session_state.selected_context_ids
                    button_text = "ä»ä¸Šä¸‹æ–‡ä¸­ç§»é™¤ (Remove from Context)" if is_in_context else "åŠ å…¥åˆ°ä¸Šä¸‹æ–‡ (Add to Context)"
                    if st.button(button_text, key=f"ctx_btn_{st.session_state.selected_node_id}"):
                        if is_in_context:
                            st.session_state.selected_context_ids.remove(st.session_state.selected_node_id)
                        else:
                            # Avoid adding duplicates
                            if st.session_state.selected_node_id not in st.session_state.selected_context_ids:
                                 st.session_state.selected_context_ids.append(st.session_state.selected_node_id)
                        st.rerun() # Update UI

                    # Display details in expanders
                    with st.expander("æ‘˜è¦ (Summary)"):
                         summary = selected_node_data.get('summary')
                         st.markdown(summary if summary and not summary.startswith("[") else "*æ— æœ‰æ•ˆæ‘˜è¦ (No valid summary)*")
                    with st.expander("ä»£ç ç‰‡æ®µ (Code Snippet)"):
                         st.code(selected_node_data.get('code', '# N/A'), language='python')
                    with st.expander("æå–çš„å…³ç³» (Extracted Relationships)"):
                         rels = selected_node_data.get('relationships')
                         if rels:
                              st.json(rels)
                         else:
                              st.markdown("*æœªæå–åˆ°å…³ç³»æˆ–æ— å…³ç³»ã€‚(No relationships extracted or none found.)*")
                    st.divider()
                else:
                    st.warning(f"é€‰ä¸­çš„èŠ‚ç‚¹ ID '{st.session_state.selected_node_id}' åœ¨å›¾ä¸­æœªæ‰¾åˆ°ã€‚è¯·é‡æ–°é€‰æ‹©ã€‚(Selected node ID not found in graph. Please reselect.)")
                    st.session_state.selected_node_id = None # Reset selection

            else:
                 st.info("è¯·åœ¨å·¦ä¾§å›¾ä¸­ç‚¹å‡»ä¸€ä¸ªèŠ‚ç‚¹ä»¥æŸ¥çœ‹å…¶è¯¦ç»†ä¿¡æ¯ã€‚(Click a node in the graph on the left to see details.)")


            # Display Current Context
            st.markdown("---")
            st.markdown("**å½“å‰ä¸Šä¸‹æ–‡ (Current Context):**")
            if st.session_state.selected_context_ids:
                 context_display_list = []
                 for ctx_id in st.session_state.selected_context_ids:
                      # Try to get node data for display name
                      ctx_node_data = None
                      if st.session_state.graph and ctx_id in st.session_state.graph.nodes:
                           ctx_node_data = st.session_state.graph.nodes[ctx_id]
                           display_name = f"`{ctx_node_data.get('short_name', ctx_id)}` ({ctx_node_data.get('type', 'N/A')})"
                      else:
                           # Fallback if graph data isn't available for the ID
                           display_name = f"`{ctx_id}`"
                      context_display_list.append(f"- {display_name}")
                 st.markdown("\n".join(context_display_list))

                 if st.button("æ¸…ç©ºä¸Šä¸‹æ–‡ (Clear Context)", key="clear_ctx"):
                      st.session_state.selected_context_ids = []
                      st.rerun()
            else:
                 st.markdown("*æœªé€‰æ‹©ä»»ä½•ä¸Šä¸‹æ–‡ã€‚å°†è‡ªåŠ¨æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚(No context selected. Relevant information will be retrieved automatically.)*")


            # RAG Q&A Section
            st.markdown("---")
            st.markdown("**æé—® (Ask Questions):**")
            question = st.text_area("è¾“å…¥æ‚¨å…³äºä»£ç çš„é—®é¢˜ (Enter your question about the code):", key="rag_question_input", value=st.session_state.last_rag_question)
            ask_rag_button = st.button("æé—® (Ask)", key="ask_rag")

            if ask_rag_button and question:
                 st.session_state.last_rag_question = question
                 st.session_state.last_rag_answer = "" # Clear previous answer
                 retrieved_chunks_for_q: List[Dict[str, Any]] = []

                 if not st.session_state.rag_handler_instance:
                      st.error("RAG ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•å›ç­”é—®é¢˜ã€‚(RAG system not initialized.)")
                 else:
                      with st.spinner("æ­£åœ¨æ£€ç´¢ç›¸å…³ä»£ç å—... (Retrieving relevant code chunks...)"):
                           try:
                               # If context is selected, retrieve those chunks directly
                               if st.session_state.selected_context_ids:
                                    logger.info(f"Using {len(st.session_state.selected_context_ids)} selected context nodes for RAG.")
                                    for ctx_id in st.session_state.selected_context_ids:
                                         # Use RAG handler to get full chunk data by ID
                                         chunk_data = st.session_state.rag_handler_instance.get_chunk_by_id(ctx_id)
                                         if chunk_data:
                                              retrieved_chunks_for_q.append(chunk_data)
                                         else:
                                              logger.warning(f"Could not retrieve chunk data for context ID: {ctx_id}")
                                    # Optionally, still perform a vector search to augment the context?
                                    # retrieved_chunks_for_q.extend(st.session_state.rag_handler_instance.retrieve(question, k=2))
                                    # Deduplicate if needed: retrieved_chunks_for_q = list({c['id']: c for c in retrieved_chunks_for_q}.values())
                               else:
                                    logger.info("No context selected, performing vector search for RAG.")
                                    retrieved_chunks_for_q = st.session_state.rag_handler_instance.retrieve(question, k=5) # Retrieve top 5

                           except Exception as retrieve_err:
                                st.error(f"æ£€ç´¢æ—¶å‡ºé”™ (Error during retrieval): {retrieve_err}")
                                logger.error("Error during RAG retrieval", exc_info=True)

                      # Proceed to generation if retrieval was attempted (even if it returned empty)
                      with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”... (Generating answer...)"):
                           try:
                                st.session_state.last_rag_answer = st.session_state.rag_handler_instance.generate_response(
                                    question,
                                    retrieved_chunks_for_q # Pass retrieved chunks (could be empty)
                                )
                           except Exception as gen_err:
                                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™ (Error during generation): {gen_err}")
                                logger.error("Error during RAG generation", exc_info=True)
                                st.session_state.last_rag_answer = "[ç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯ (Error during generation)]"
                 st.rerun() # Update UI to show answer or errors

            # Display last Q&A
            if st.session_state.last_rag_answer:
                 st.markdown("**å›ç­” (Answer):**")
                 st.markdown(st.session_state.last_rag_answer)

    elif st.session_state.analysis_error:
         # Show error prominently if analysis failed before completion
         st.error(f"åˆ†ææœªèƒ½å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¾§è¾¹æ é”™è¯¯ä¿¡æ¯ã€‚(Analysis could not complete. See error in sidebar.)")
    else:
        # Initial state before analysis
        st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©é¡¹ç›®å¹¶ç‚¹å‡» 'åˆ†æé¡¹ç›®' ä»¥å¯åŠ¨ã€‚(Select a project and click 'Analyze Project' on the left to start.)")

